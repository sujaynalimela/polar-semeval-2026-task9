{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **POLAR @ SemEval-2026 ‚Äî Task9**\n",
    "## Subtask 1: Polarization Detection    \n",
    "### Authors: Sujay Nalimela, Vedant Kesharia, Gaurav Shinde\n",
    "### Date: December 2025\n",
    "\n",
    "---\n",
    "\n",
    "This notebook contains the *full pipeline* for all POLAR shared task subtasks:\n",
    "\n",
    "### ‚úî Subtask 1 ‚Äî Polarization Detection (binary)  \n",
    "### ‚úî Subtask 2 ‚Äî Polarization Type Classification (multi-class)  \n",
    "### ‚úî Subtask 3 ‚Äî Polarization Manifestation Identification\n",
    "\n",
    "**Task Overview:**\n",
    "- **Subtask 1**: Binary classification to detect if text contains polarization\n",
    "- **Subtask 2**: Multi-label classification to identify types of polarization (political, racial/ethnic, religious, gender/sexual, other)\n",
    "- **Subtask 3**: Multi-label classification to identify how polarization manifests (stereotype, vilification, dehumanization, extreme_language, lack_of_empathy, invalidation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup and Cleanup\n",
    "\n",
    "Clean up working directory and cache to ensure fresh start and avoid conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T08:12:50.286616Z",
     "iopub.status.busy": "2025-12-07T08:12:50.285879Z",
     "iopub.status.idle": "2025-12-07T08:12:50.407661Z",
     "shell.execute_reply": "2025-12-07T08:12:50.406861Z",
     "shell.execute_reply.started": "2025-12-07T08:12:50.286587Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# rm -rf /kaggle/working/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T08:12:57.104417Z",
     "iopub.status.busy": "2025-12-07T08:12:57.104109Z",
     "iopub.status.idle": "2025-12-07T08:12:57.221969Z",
     "shell.execute_reply": "2025-12-07T08:12:57.221187Z",
     "shell.execute_reply.started": "2025-12-07T08:12:57.104389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# rm -rf /root/.cache/huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:15:49.915849Z",
     "iopub.status.busy": "2025-12-08T01:15:49.915232Z",
     "iopub.status.idle": "2025-12-08T01:15:53.331985Z",
     "shell.execute_reply": "2025-12-08T01:15:53.331437Z",
     "shell.execute_reply.started": "2025-12-08T01:15:49.915824Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:15:54.056329Z",
     "iopub.status.busy": "2025-12-08T01:15:54.055560Z",
     "iopub.status.idle": "2025-12-08T01:15:54.730020Z",
     "shell.execute_reply": "2025-12-08T01:15:54.729132Z",
     "shell.execute_reply.started": "2025-12-08T01:15:54.056304Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'polar-semeval-2026-task9'...\n",
      "remote: Enumerating objects: 39, done.\u001b[K\n",
      "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
      "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
      "remote: Total 39 (delta 11), reused 16 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (39/39), 19.57 KiB | 4.89 MiB/s, done.\n",
      "Resolving deltas: 100% (11/11), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sujaynalimela/polar-semeval-2026-task9.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:15:58.692913Z",
     "iopub.status.busy": "2025-12-08T01:15:58.692141Z",
     "iopub.status.idle": "2025-12-08T01:15:58.697175Z",
     "shell.execute_reply": "2025-12-08T01:15:58.696453Z",
     "shell.execute_reply.started": "2025-12-08T01:15:58.692884Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/kaggle/working', '/kaggle/lib/kagglegym', '/kaggle/lib', '/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '', '/usr/local/lib/python3.11/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.11/dist-packages/IPython/extensions', '/root/.ipython', '/kaggle/working/polar-semeval-2026-task9']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/kaggle/working/polar-semeval-2026-task9\")\n",
    "\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:16:00.845435Z",
     "iopub.status.busy": "2025-12-08T01:16:00.844913Z",
     "iopub.status.idle": "2025-12-08T01:16:30.265779Z",
     "shell.execute_reply": "2025-12-08T01:16:30.264974Z",
     "shell.execute_reply.started": "2025-12-08T01:16:00.845397Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 01:16:11.700071: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765156571.891858      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765156571.951828      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "from shared.preprocess import clean_text\n",
    "from shared.metrics import macro_f1\n",
    "\n",
    "torch.backends.mps.allow_tf32 = True\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with **Subtask 1 (binary)** using **XLM-RoBERTa-Base**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration and Hyperparameters\n",
    "\n",
    "Set all training parameters, paths, and model configuration:\n",
    "- **Model**: LaBSE (Language-agnostic BERT Sentence Embedding), also tried on bert, indicbert, muril and xlm roberta models\n",
    "- **Language**: Current language Chinese (zho) - also tried on hindi and english\n",
    "- **Max Length**: 224 tokens for efficient training\n",
    "- **Training**: 10 epochs with learning rate 2e-5\n",
    "- **Hardware**: GPU (P100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:16:33.214330Z",
     "iopub.status.busy": "2025-12-08T01:16:33.214023Z",
     "iopub.status.idle": "2025-12-08T01:16:33.218958Z",
     "shell.execute_reply": "2025-12-08T01:16:33.218161Z",
     "shell.execute_reply.started": "2025-12-08T01:16:33.214307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BASE_DATA = \"/kaggle/input/datasetphase2/data2\"\n",
    "LANG = \"zho\"  # change to arb, spa, amh, etc.\n",
    "\n",
    "MODEL_NAME = \"sentence-transformers/LaBSE\"\n",
    "MAX_LEN = 224\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 4\n",
    "GRAD_ACCUM = 2\n",
    "LR = 2e-5\n",
    "WARMUP_RATIO = 0.06\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "# Subtask 1 overrides\n",
    "SUBTASK1_EPOCHS = 10\n",
    "SUBTASK1_LR = 2e-5\n",
    "\n",
    "# Subtask 2 overrides\n",
    "SUBTASK2_EPOCHS = 10\n",
    "SUBTASK2_LR = 2e-5\n",
    "\n",
    "# Subtask 3 overrides\n",
    "SUBTASK3_EPOCHS = 5\n",
    "SUBTASK3_LR = 1.5e-5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Dataset**\n",
    "\n",
    "Each language includes:\n",
    "\n",
    "- `train/<lang>.csv`  \n",
    "- `dev/<lang>.csv`  \n",
    "- `test/<lang>.csv`  \n",
    "\n",
    "We read all splits and inspect the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:16:35.551567Z",
     "iopub.status.busy": "2025-12-08T01:16:35.551286Z",
     "iopub.status.idle": "2025-12-08T01:16:35.581560Z",
     "shell.execute_reply": "2025-12-08T01:16:35.580907Z",
     "shell.execute_reply.started": "2025-12-08T01:16:35.551545Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4280\n",
      "Dev size: 214\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>polarization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zho_e59ce789a1d83d91cb7d362efaa3bf23</td>\n",
       "      <td>Â•Ω‰πÖÈÉΩÊ≤°ÊúâËßÅËøáÈÇ£‰πàÂπ≤ÂáÄÁöÑÁôΩ‰∫∫Áè≠Á∫ß‰∫ÜÔºå‰∏Ä‰∏™Èªë‰πêËâ≤ÈÉΩÊ≤°Êúâ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zho_ea3ef5567698fc40fa631baf7f697a16</td>\n",
       "      <td>Ê•º‰∏ªËøôËÆΩÂà∫Â§™ÊúâÂäõÂ∫¶ÊääË∑™Ëô´ÊóèÂíåÂõΩÈôÖÈ¨ºÂ≠êËô´Á±ªÂèäÂÖ∂ÂÆÉ‰ª¨Âêé‰ª£Ëô´Ê∑∑ÊèèÂÜôÊ∑ãÊºìÂ∞ΩËá¥</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zho_b73779673957f6dab5688c27a6747458</td>\n",
       "      <td>‰Ω†ËøôÊ†∑ËØ¥ËÆ©ÈÇ£‰∫õÊ†áÊ¶úÊâæ‰∏™Â§ñÂõΩÂØπË±°ÂÄçÊúâÈù¢ÁöÑ‰∫∫ËøòÊÄé‰πàË£ÖbÔøΩ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zho_f7164a14baafbcb6ec387b0217a1c766</td>\n",
       "      <td>ËØ¥Êòé‰∏Ä‰∏ãÔºåÊàëÂè™ÂÖ≥Áà±Ëá™Â∑±Ë∫´ËæπÁöÑÂ•≥ÊÄßÔºåÊØîÂ¶ÇËÄÅÂ©ÜÂ•≥ÂÑøÁ≠âÔºåÂà´ÁöÑÂ•≥‰∫∫ÂÖ≥ÊàëÈ∏ü‰∫ã„ÄÇv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zho_1be506c572b805494787f548671a5bb7</td>\n",
       "      <td>Âü∫‰Ω¨ËøòËØ¥‰πãÂâçËßÜÈ¢ëÈáåÁöÑ‰∏çÊòØÂÆÉÔºåÂÆÉÈÉΩËØ¥ÁÖßÁâáÊòØÂÆÉÁàÜÂá∫Êù•ÁöÑ‰∫Ü„ÄÇ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                                 text  \\\n",
       "0  zho_e59ce789a1d83d91cb7d362efaa3bf23           Â•Ω‰πÖÈÉΩÊ≤°ÊúâËßÅËøáÈÇ£‰πàÂπ≤ÂáÄÁöÑÁôΩ‰∫∫Áè≠Á∫ß‰∫ÜÔºå‰∏Ä‰∏™Èªë‰πêËâ≤ÈÉΩÊ≤°Êúâ   \n",
       "1  zho_ea3ef5567698fc40fa631baf7f697a16   Ê•º‰∏ªËøôËÆΩÂà∫Â§™ÊúâÂäõÂ∫¶ÊääË∑™Ëô´ÊóèÂíåÂõΩÈôÖÈ¨ºÂ≠êËô´Á±ªÂèäÂÖ∂ÂÆÉ‰ª¨Âêé‰ª£Ëô´Ê∑∑ÊèèÂÜôÊ∑ãÊºìÂ∞ΩËá¥   \n",
       "2  zho_b73779673957f6dab5688c27a6747458           ‰Ω†ËøôÊ†∑ËØ¥ËÆ©ÈÇ£‰∫õÊ†áÊ¶úÊâæ‰∏™Â§ñÂõΩÂØπË±°ÂÄçÊúâÈù¢ÁöÑ‰∫∫ËøòÊÄé‰πàË£ÖbÔøΩ   \n",
       "3  zho_f7164a14baafbcb6ec387b0217a1c766  ËØ¥Êòé‰∏Ä‰∏ãÔºåÊàëÂè™ÂÖ≥Áà±Ëá™Â∑±Ë∫´ËæπÁöÑÂ•≥ÊÄßÔºåÊØîÂ¶ÇËÄÅÂ©ÜÂ•≥ÂÑøÁ≠âÔºåÂà´ÁöÑÂ•≥‰∫∫ÂÖ≥ÊàëÈ∏ü‰∫ã„ÄÇv   \n",
       "4  zho_1be506c572b805494787f548671a5bb7          Âü∫‰Ω¨ËøòËØ¥‰πãÂâçËßÜÈ¢ëÈáåÁöÑ‰∏çÊòØÂÆÉÔºåÂÆÉÈÉΩËØ¥ÁÖßÁâáÊòØÂÆÉÁàÜÂá∫Êù•ÁöÑ‰∫Ü„ÄÇ   \n",
       "\n",
       "   polarization  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = f\"{BASE_DATA}/subtask1/train/{LANG}.csv\"\n",
    "dev_path   = f\"{BASE_DATA}/subtask1/dev/{LANG}.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "dev_df   = pd.read_csv(dev_path)\n",
    "\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Dev size:\", len(dev_df))\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocessing**\n",
    "\n",
    "We apply light normalization (lowercasing, URL removal, emoji normalization)\n",
    "using our shared `clean_text()` function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Text Preprocessing\n",
    "\n",
    "Apply text cleaning pipeline:\n",
    "- Lowercase normalization\n",
    "- URL removal\n",
    "- Emoji standardization\n",
    "- Special character handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:16:37.982293Z",
     "iopub.status.busy": "2025-12-08T01:16:37.981995Z",
     "iopub.status.idle": "2025-12-08T01:16:38.127029Z",
     "shell.execute_reply": "2025-12-08T01:16:38.126240Z",
     "shell.execute_reply.started": "2025-12-08T01:16:37.982271Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df[\"text\"] = train_df[\"text\"].apply(clean_text)\n",
    "dev_df[\"text\"]   = dev_df[\"text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:16:39.698008Z",
     "iopub.status.busy": "2025-12-08T01:16:39.697208Z",
     "iopub.status.idle": "2025-12-08T01:16:39.709419Z",
     "shell.execute_reply": "2025-12-08T01:16:39.708517Z",
     "shell.execute_reply.started": "2025-12-08T01:16:39.697983Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights (neg,pos): [0.5044392347335815, 0.49556073546409607]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# def tune_binary_threshold(logits, labels, grid=None):\n",
    "#     grid = grid or np.linspace(0.1, 0.9, 17)\n",
    "#     probs = torch.softmax(torch.tensor(logits), dim=1)[:, 1].numpy()\n",
    "#     best_f1, best_t = -1, 0.5\n",
    "#     for t in grid:\n",
    "#         preds = (probs >= t).astype(int)\n",
    "#         score = f1_score(labels, preds)\n",
    "#         if score > best_f1:\n",
    "#             best_f1, best_t = score, t\n",
    "#     return best_t, best_f1\n",
    "\n",
    "def tune_binary_threshold(logits, labels, grid=None):\n",
    "    grid = grid or np.linspace(0.1, 0.9, 17)\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1)[:, 1].numpy()\n",
    "    best_f1, best_t = -1, 0.5\n",
    "    for t in grid:\n",
    "        preds = (probs >= t).astype(int)\n",
    "        score = f1_score(labels, preds, average=\"macro\")\n",
    "        if score > best_f1:\n",
    "            best_f1, best_t = score, t\n",
    "    return best_t, best_f1\n",
    "\n",
    "def tune_multilabel_threshold(logits, labels, grid=None):\n",
    "    grid = grid or np.linspace(0.1, 0.8, 15)\n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    best_f1, best_t = -1, 0.5\n",
    "    for t in grid:\n",
    "        preds = (probs >= t).astype(int)\n",
    "        score = f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "        if score > best_f1:\n",
    "            best_f1, best_t = score, t\n",
    "    return best_t, best_f1\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        base_model = model.module if hasattr(model, \"module\") else model\n",
    "        outputs = model(**inputs)\n",
    "        if self.class_weights is not None:\n",
    "            device = next(model.parameters()).device\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=self.class_weights.to(device))\n",
    "            loss = loss_fct(outputs.logits.view(-1, base_model.config.num_labels), labels.view(-1))\n",
    "        else:\n",
    "            loss = outputs.loss\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "class BCETrainer(Trainer):\n",
    "    def __init__(self, *args, pos_weight=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.pos_weight = pos_weight\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        base_model = model.module if hasattr(model, \"module\") else model\n",
    "        device = next(model.parameters()).device\n",
    "        loss_fct = nn.BCEWithLogitsLoss(\n",
    "            pos_weight=self.pos_weight.to(device) if self.pos_weight is not None else None\n",
    "        )\n",
    "        loss = loss_fct(outputs.logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# class weights for Subtask 1\n",
    "pos_frac = train_df[\"polarization\"].mean()\n",
    "class_weights = torch.tensor([1 - pos_frac, pos_frac], dtype=torch.float)\n",
    "print(\"Class weights (neg,pos):\", class_weights.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:16:43.289963Z",
     "iopub.status.busy": "2025-12-08T01:16:43.289175Z",
     "iopub.status.idle": "2025-12-08T01:16:43.321952Z",
     "shell.execute_reply": "2025-12-08T01:16:43.321221Z",
     "shell.execute_reply.started": "2025-12-08T01:16:43.289931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df_split, val_df_split = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.1,\n",
    "    stratify=train_df[\"polarization\"],\n",
    "    random_state=42\n",
    ")\n",
    "train_dataset = Dataset.from_pandas(train_df_split)\n",
    "val_dataset   = Dataset.from_pandas(val_df_split)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tokenization**\n",
    "\n",
    "We use a single tokenizer across all languages (multilingual model).\n",
    "\n",
    "Convert text to model inputs using the LaBSE tokenizer:\n",
    "- Truncate sequences to MAX_LEN tokens\n",
    "- Pad shorter sequences to MAX_LEN\n",
    "- Generate attention masks\n",
    "- Prepare for PyTorch Trainer\n",
    "\n",
    "The tokenizer handles multiple scripts (Latin, Devanagari, Arabic, etc.) seamlessly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:16:46.595166Z",
     "iopub.status.busy": "2025-12-08T01:16:46.594398Z",
     "iopub.status.idle": "2025-12-08T01:16:50.478807Z",
     "shell.execute_reply": "2025-12-08T01:16:50.477977Z",
     "shell.execute_reply.started": "2025-12-08T01:16:46.595135Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f4120743684817926944aa2f85d102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/397 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c4dffa26674efbab1d2f550d0dc1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/804 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c814a819c08a4d4c96a9a2c3f0f74eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1786f89a34c34d5e8c6a43648847f8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddc742ad67f4fb183ceeedfae06353c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531d1fd5bdb8457e8851cfd27a3abc65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3852 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6792ac3239ec4ff2b5210a5880c5be84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LEN\n",
    "    )\n",
    "\n",
    "# tokenization\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "val_dataset   = val_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# rename correct label column\n",
    "train_dataset = train_dataset.rename_column(\"polarization\", \"labels\")\n",
    "val_dataset   = val_dataset.rename_column(\"polarization\", \"labels\")\n",
    "\n",
    "# set PyTorch formatting\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T23:57:03.815664Z",
     "iopub.status.busy": "2025-12-07T23:57:03.815298Z",
     "iopub.status.idle": "2025-12-07T23:57:10.458572Z",
     "shell.execute_reply": "2025-12-07T23:57:10.457790Z",
     "shell.execute_reply.started": "2025-12-07T23:57:03.815644Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68004de64a74cb98bdef177aa67f48d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/LaBSE and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Train Subtask 1 Model\n",
    "\n",
    "Train the binary classification model using WeightedTrainer with class weights.\n",
    "\n",
    "**Training Process:**\n",
    "1. Forward pass with mixed precision\n",
    "2. Compute weighted cross-entropy loss\n",
    "3. Backward pass with gradient accumulation\n",
    "4. Update weights every 2 gradient accumulation steps\n",
    "5. Evaluate on validation set after each epoch\n",
    "6. Save best model based on macro F1\n",
    "\n",
    "**Expected Training Time**: ~15-25 minutes on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-07T23:30:57.047Z",
     "iopub.execute_input": "2025-12-07T23:30:50.109525Z",
     "iopub.status.busy": "2025-12-07T23:30:50.108936Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47/506938794.py:38: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='3090' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  15/3090 00:04 < 18:21, 2.79 it/s, Epoch 0.05/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/temp/subtask1\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    learning_rate=SUBTASK1_LR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM,\n",
    "    # per_device_train_batch_size=2,\n",
    "    # per_device_eval_batch_size=16,\n",
    "    # gradient_accumulation_steps=4,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1)[:, 1].numpy()\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    return {\"macro_f1\": f1_score(labels, preds, average=\"macro\")}\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    class_weights=class_weights,\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-07T23:30:57.048Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_pred = trainer.predict(val_dataset)\n",
    "best_threshold_sub1, best_val_f1_sub1 = tune_binary_threshold(val_pred.predictions, val_pred.label_ids)\n",
    "print(f\"Best val threshold (Subtask 1): {best_threshold_sub1:.2f} | F1={best_val_f1_sub1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T08:06:58.487743Z",
     "iopub.status.busy": "2025-12-07T08:06:58.487072Z",
     "iopub.status.idle": "2025-12-07T08:06:58.491130Z",
     "shell.execute_reply": "2025-12-07T08:06:58.490341Z",
     "shell.execute_reply.started": "2025-12-07T08:06:58.487720Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# full_train_dataset = Dataset.from_pandas(train_df)\n",
    "\n",
    "# full_train_dataset = full_train_dataset.map(tokenize, batched=True)\n",
    "# full_train_dataset = full_train_dataset.rename_column(\"polarization\", \"labels\")\n",
    "# full_train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# full_training_args = TrainingArguments(\n",
    "#     output_dir=f\"subtask1/{LANG}_checkpoints\",\n",
    "#     eval_strategy=\"no\",       # ‚õî Disable evaluation\n",
    "#     save_strategy=\"no\",       # Optional: don‚Äôt save intermediate checkpoints\n",
    "#     learning_rate=3e-5,\n",
    "#     per_device_train_batch_size=4,\n",
    "#     num_train_epochs=2,\n",
    "#     logging_steps=50,\n",
    "#     report_to=\"none\"\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=full_training_args,\n",
    "#     train_dataset=full_train_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "\n",
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T19:39:37.503185Z",
     "iopub.status.busy": "2025-12-07T19:39:37.502869Z",
     "iopub.status.idle": "2025-12-07T19:39:37.536247Z",
     "shell.execute_reply": "2025-12-07T19:39:37.535526Z",
     "shell.execute_reply.started": "2025-12-07T19:39:37.503163Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test (dev) size: 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>polarization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hin_4e26c967ea5fd015078d088118fb623c</td>\n",
       "      <td>‡§î‡§∞ ‡§á‡§∏ ‡§§‡§∞‡§π ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§®‡•á ‡§Ö‡§™‡§®‡§æ ‡§á‡§∏‡•ç‡§≤‡§æ‡§Æ‡•Ä‡§ï‡§∞‡§£ ‡§ï‡§∞ ‡§≤‡§ø‡§Ø‡§æ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hin_ad83fddd1620ad95784072561ea3d3d0</td>\n",
       "      <td>‡§ì‡§∞‡•Ä‡§ú‡§®‡§≤ ‡§π‡§ø‡§Ç‡§¶‡•Å‡§§‡•ç‡§µ ‡§Ø‡§π‡•Ä ‡§π‡•à ‡•§</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hin_21522a5233b239644c874f8b52890d70</td>\n",
       "      <td>‡§π‡§ø‡§Ç‡§¶‡•Å‡§§‡•ç‡§µ ‡§ï‡•Ä ‡§ö‡§∞‡•ç‡§¨‡•Ä ‡§â‡§§‡§∞ ‡§ó‡§à</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hin_b7fa87154f21b0abd1eac2c3973c7812</td>\n",
       "      <td>‡§π‡§ø‡§Ç‡§¶‡•Ç ‡§è‡§µ‡§Æ ‡§π‡§ø‡§Ç‡§¶‡•Å‡§§‡•ç‡§µ ‡§ú‡§æ‡§ó ‡§∞‡§π‡§æ ‡§π‡•à‡•§ ‡§ú‡§Ø ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hin_d3e4ed943e52657cc4ad3c76d6747d60</td>\n",
       "      <td>‡§¨‡•ã‡§≤ ‡§Ö‡§™‡§®‡•á ‡§Ü‡§ï‡§æ ‡§ï‡•ã ‡§π‡§ø‡§®‡•ç‡§¶‡•Ç ‡§î‡§∞ ‡§π‡§ø‡§Ç‡§¶‡•Å‡§§‡•ç‡§µ ‡§π‡•à .......‡§ò...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  hin_4e26c967ea5fd015078d088118fb623c   \n",
       "1  hin_ad83fddd1620ad95784072561ea3d3d0   \n",
       "2  hin_21522a5233b239644c874f8b52890d70   \n",
       "3  hin_b7fa87154f21b0abd1eac2c3973c7812   \n",
       "4  hin_d3e4ed943e52657cc4ad3c76d6747d60   \n",
       "\n",
       "                                                text  polarization  \n",
       "0        ‡§î‡§∞ ‡§á‡§∏ ‡§§‡§∞‡§π ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä ‡§®‡•á ‡§Ö‡§™‡§®‡§æ ‡§á‡§∏‡•ç‡§≤‡§æ‡§Æ‡•Ä‡§ï‡§∞‡§£ ‡§ï‡§∞ ‡§≤‡§ø‡§Ø‡§æ           NaN  \n",
       "1                           ‡§ì‡§∞‡•Ä‡§ú‡§®‡§≤ ‡§π‡§ø‡§Ç‡§¶‡•Å‡§§‡•ç‡§µ ‡§Ø‡§π‡•Ä ‡§π‡•à ‡•§           NaN  \n",
       "2                           ‡§π‡§ø‡§Ç‡§¶‡•Å‡§§‡•ç‡§µ ‡§ï‡•Ä ‡§ö‡§∞‡•ç‡§¨‡•Ä ‡§â‡§§‡§∞ ‡§ó‡§à           NaN  \n",
       "3         ‡§π‡§ø‡§Ç‡§¶‡•Ç ‡§è‡§µ‡§Æ ‡§π‡§ø‡§Ç‡§¶‡•Å‡§§‡•ç‡§µ ‡§ú‡§æ‡§ó ‡§∞‡§π‡§æ ‡§π‡•à‡•§ ‡§ú‡§Ø ‡§∂‡•ç‡§∞‡•Ä ‡§∞‡§æ‡§Æ           NaN  \n",
       "4  ‡§¨‡•ã‡§≤ ‡§Ö‡§™‡§®‡•á ‡§Ü‡§ï‡§æ ‡§ï‡•ã ‡§π‡§ø‡§®‡•ç‡§¶‡•Ç ‡§î‡§∞ ‡§π‡§ø‡§Ç‡§¶‡•Å‡§§‡•ç‡§µ ‡§π‡•à .......‡§ò...           NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------- Load official test data (dev/) --------------------\n",
    "\n",
    "dev_pred_path = f\"{BASE_DATA}/dev/{LANG}.csv\"\n",
    "test_df = pd.read_csv(dev_pred_path)\n",
    "\n",
    "print(\"Loaded test (dev) size:\", len(test_df))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T19:39:41.119386Z",
     "iopub.status.busy": "2025-12-07T19:39:41.119051Z",
     "iopub.status.idle": "2025-12-07T19:39:41.139944Z",
     "shell.execute_reply": "2025-12-07T19:39:41.139166Z",
     "shell.execute_reply.started": "2025-12-07T19:39:41.119364Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Clean text using your preprocessing function\n",
    "test_df[\"text\"] = test_df[\"text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T19:39:43.033171Z",
     "iopub.status.busy": "2025-12-07T19:39:43.032856Z",
     "iopub.status.idle": "2025-12-07T19:39:43.060922Z",
     "shell.execute_reply": "2025-12-07T19:39:43.060367Z",
     "shell.execute_reply.started": "2025-12-07T19:39:43.033147Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare inputs\n",
    "inputs = tokenizer(\n",
    "    test_df[\"text\"].tolist(),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=MAX_LEN,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Move to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T19:39:46.492143Z",
     "iopub.status.busy": "2025-12-07T19:39:46.491823Z",
     "iopub.status.idle": "2025-12-07T19:39:46.933000Z",
     "shell.execute_reply": "2025-12-07T19:39:46.932225Z",
     "shell.execute_reply.started": "2025-12-07T19:39:46.492090Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Disable gradient calculation for faster inference\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "probs = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
    "preds = (probs >= best_threshold_sub1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T19:39:48.675211Z",
     "iopub.status.busy": "2025-12-07T19:39:48.674909Z",
     "iopub.status.idle": "2025-12-07T19:39:48.683083Z",
     "shell.execute_reply": "2025-12-07T19:39:48.682376Z",
     "shell.execute_reply.started": "2025-12-07T19:39:48.675188Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>polarization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hin_4e26c967ea5fd015078d088118fb623c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hin_ad83fddd1620ad95784072561ea3d3d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hin_21522a5233b239644c874f8b52890d70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hin_b7fa87154f21b0abd1eac2c3973c7812</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hin_d3e4ed943e52657cc4ad3c76d6747d60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  polarization\n",
       "0  hin_4e26c967ea5fd015078d088118fb623c             1\n",
       "1  hin_ad83fddd1620ad95784072561ea3d3d0             1\n",
       "2  hin_21522a5233b239644c874f8b52890d70             1\n",
       "3  hin_b7fa87154f21b0abd1eac2c3973c7812             1\n",
       "4  hin_d3e4ed943e52657cc4ad3c76d6747d60             1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    \"id\": test_df[\"id\"],\n",
    "    \"polarization\": preds.astype(int)\n",
    "})\n",
    "\n",
    "submission_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T19:39:51.762282Z",
     "iopub.status.busy": "2025-12-07T19:39:51.761518Z",
     "iopub.status.idle": "2025-12-07T19:39:51.769753Z",
     "shell.execute_reply": "2025-12-07T19:39:51.769013Z",
     "shell.execute_reply.started": "2025-12-07T19:39:51.762254Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>polarization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hin_4e26c967ea5fd015078d088118fb623c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hin_ad83fddd1620ad95784072561ea3d3d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hin_21522a5233b239644c874f8b52890d70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hin_b7fa87154f21b0abd1eac2c3973c7812</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hin_d3e4ed943e52657cc4ad3c76d6747d60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  polarization\n",
       "0  hin_4e26c967ea5fd015078d088118fb623c             1\n",
       "1  hin_ad83fddd1620ad95784072561ea3d3d0             1\n",
       "2  hin_21522a5233b239644c874f8b52890d70             1\n",
       "3  hin_b7fa87154f21b0abd1eac2c3973c7812             1\n",
       "4  hin_d3e4ed943e52657cc4ad3c76d6747d60             1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    \"id\": test_df[\"id\"],\n",
    "    \"polarization\": preds.astype(int)\n",
    "})\n",
    "\n",
    "submission_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T19:39:54.913429Z",
     "iopub.status.busy": "2025-12-07T19:39:54.912702Z",
     "iopub.status.idle": "2025-12-07T19:39:54.923010Z",
     "shell.execute_reply": "2025-12-07T19:39:54.922286Z",
     "shell.execute_reply.started": "2025-12-07T19:39:54.913405Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved prediction file: submissions/subtask1/pred_hin.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "SAVE_DIR = \"submissions/subtask1\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "OUT_PATH = f\"{SAVE_DIR}/pred_{LANG}.csv\"\n",
    "submission_df.to_csv(OUT_PATH, index=False)\n",
    "\n",
    "print(\"Saved prediction file:\", OUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T19:39:59.477181Z",
     "iopub.status.busy": "2025-12-07T19:39:59.476471Z",
     "iopub.status.idle": "2025-12-07T19:39:59.515628Z",
     "shell.execute_reply": "2025-12-07T19:39:59.514856Z",
     "shell.execute_reply.started": "2025-12-07T19:39:59.477154Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ZIP: subtask_1.zip\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "zip_name = \"subtask_1\"   # final file will be submission_subtask1.zip\n",
    "shutil.make_archive(zip_name, \"zip\", SAVE_DIR)\n",
    "\n",
    "print(\"Created ZIP:\", zip_name + \".zip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------\n",
    "# SUBTASK 2 ‚Äî Polarization Type Classification\n",
    "# ----------------------------------------------\n",
    "\n",
    "This section implements **Subtask 2** of POLAR @ SemEval-2026.\n",
    "\n",
    "### ‚úî Objective  \n",
    "Given a text, predict which *types* of polarization apply:\n",
    "\n",
    "- `political`\n",
    "- `racial/ethnic`\n",
    "- `religious`\n",
    "- `gender/sexual`\n",
    "- `other`\n",
    "\n",
    "This is a **multi-label classification task** ‚Üí each text may have multiple 1s.\n",
    "\n",
    "### ‚úî Notes\n",
    "- Subtask 2 is trained **independently** from Subtask 1.\n",
    "- Dataset contains **only train + test**, so we split train into *train/validation*.\n",
    "- We reuse the same multilingual model (`bert-base-multilingual-cased`) as Subtask 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:32:36.994027Z",
     "iopub.status.busy": "2025-12-08T00:32:36.993679Z",
     "iopub.status.idle": "2025-12-08T00:32:37.041570Z",
     "shell.execute_reply": "2025-12-08T00:32:37.040877Z",
     "shell.execute_reply.started": "2025-12-08T00:32:36.994004Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUBTASK 2: Polarization Type Classification ===\n",
      "Subtask 2 train size: 4280\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>political</th>\n",
       "      <th>racial/ethnic</th>\n",
       "      <th>religious</th>\n",
       "      <th>gender/sexual</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zho_e59ce789a1d83d91cb7d362efaa3bf23</td>\n",
       "      <td>Â•Ω‰πÖÈÉΩÊ≤°ÊúâËßÅËøáÈÇ£‰πàÂπ≤ÂáÄÁöÑÁôΩ‰∫∫Áè≠Á∫ß‰∫ÜÔºå‰∏Ä‰∏™Èªë‰πêËâ≤ÈÉΩÊ≤°Êúâ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zho_ea3ef5567698fc40fa631baf7f697a16</td>\n",
       "      <td>Ê•º‰∏ªËøôËÆΩÂà∫Â§™ÊúâÂäõÂ∫¶ÊääË∑™Ëô´ÊóèÂíåÂõΩÈôÖÈ¨ºÂ≠êËô´Á±ªÂèäÂÖ∂ÂÆÉ‰ª¨Âêé‰ª£Ëô´Ê∑∑ÊèèÂÜôÊ∑ãÊºìÂ∞ΩËá¥</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zho_b73779673957f6dab5688c27a6747458</td>\n",
       "      <td>‰Ω†ËøôÊ†∑ËØ¥ËÆ©ÈÇ£‰∫õÊ†áÊ¶úÊâæ‰∏™Â§ñÂõΩÂØπË±°ÂÄçÊúâÈù¢ÁöÑ‰∫∫ËøòÊÄé‰πàË£ÖbÔøΩ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zho_f7164a14baafbcb6ec387b0217a1c766</td>\n",
       "      <td>ËØ¥Êòé‰∏Ä‰∏ãÔºåÊàëÂè™ÂÖ≥Áà±Ëá™Â∑±Ë∫´ËæπÁöÑÂ•≥ÊÄßÔºåÊØîÂ¶ÇËÄÅÂ©ÜÂ•≥ÂÑøÁ≠âÔºåÂà´ÁöÑÂ•≥‰∫∫ÂÖ≥ÊàëÈ∏ü‰∫ã„ÄÇv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zho_1be506c572b805494787f548671a5bb7</td>\n",
       "      <td>Âü∫‰Ω¨ËøòËØ¥‰πãÂâçËßÜÈ¢ëÈáåÁöÑ‰∏çÊòØÂÆÉÔºåÂÆÉÈÉΩËØ¥ÁÖßÁâáÊòØÂÆÉÁàÜÂá∫Êù•ÁöÑ‰∫Ü„ÄÇ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                                 text  \\\n",
       "0  zho_e59ce789a1d83d91cb7d362efaa3bf23           Â•Ω‰πÖÈÉΩÊ≤°ÊúâËßÅËøáÈÇ£‰πàÂπ≤ÂáÄÁöÑÁôΩ‰∫∫Áè≠Á∫ß‰∫ÜÔºå‰∏Ä‰∏™Èªë‰πêËâ≤ÈÉΩÊ≤°Êúâ   \n",
       "1  zho_ea3ef5567698fc40fa631baf7f697a16   Ê•º‰∏ªËøôËÆΩÂà∫Â§™ÊúâÂäõÂ∫¶ÊääË∑™Ëô´ÊóèÂíåÂõΩÈôÖÈ¨ºÂ≠êËô´Á±ªÂèäÂÖ∂ÂÆÉ‰ª¨Âêé‰ª£Ëô´Ê∑∑ÊèèÂÜôÊ∑ãÊºìÂ∞ΩËá¥   \n",
       "2  zho_b73779673957f6dab5688c27a6747458           ‰Ω†ËøôÊ†∑ËØ¥ËÆ©ÈÇ£‰∫õÊ†áÊ¶úÊâæ‰∏™Â§ñÂõΩÂØπË±°ÂÄçÊúâÈù¢ÁöÑ‰∫∫ËøòÊÄé‰πàË£ÖbÔøΩ   \n",
       "3  zho_f7164a14baafbcb6ec387b0217a1c766  ËØ¥Êòé‰∏Ä‰∏ãÔºåÊàëÂè™ÂÖ≥Áà±Ëá™Â∑±Ë∫´ËæπÁöÑÂ•≥ÊÄßÔºåÊØîÂ¶ÇËÄÅÂ©ÜÂ•≥ÂÑøÁ≠âÔºåÂà´ÁöÑÂ•≥‰∫∫ÂÖ≥ÊàëÈ∏ü‰∫ã„ÄÇv   \n",
       "4  zho_1be506c572b805494787f548671a5bb7          Âü∫‰Ω¨ËøòËØ¥‰πãÂâçËßÜÈ¢ëÈáåÁöÑ‰∏çÊòØÂÆÉÔºåÂÆÉÈÉΩËØ¥ÁÖßÁâáÊòØÂÆÉÁàÜÂá∫Êù•ÁöÑ‰∫Ü„ÄÇ   \n",
       "\n",
       "   political  racial/ethnic  religious  gender/sexual  other  \n",
       "0          0              1          0              0      0  \n",
       "1          0              1          0              0      0  \n",
       "2          0              1          0              0      0  \n",
       "3          0              0          0              1      0  \n",
       "4          0              0          0              1      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=== SUBTASK 2: Polarization Type Classification ===\")\n",
    "\n",
    "sub2_path = f\"/kaggle/input/datasetphase2/data2/subtask2/train/{LANG}.csv\"\n",
    "df2 = pd.read_csv(sub2_path)\n",
    "\n",
    "print(\"Subtask 2 train size:\", len(df2))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess text & prepare label columns\n",
    "\n",
    "We apply the same preprocessing (`clean_text`) used in Subtask 1.  \n",
    "Subtask 2 has **5 binary label columns**:\n",
    "\n",
    "- `political`\n",
    "- `racial/ethnic`\n",
    "- `religious`\n",
    "- `gender/sexual`\n",
    "- `other`\n",
    "\n",
    "We convert them to integer (0/1), fill missing values, and create a **multi-label target matrix**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:32:39.914599Z",
     "iopub.status.busy": "2025-12-08T00:32:39.914333Z",
     "iopub.status.idle": "2025-12-08T00:32:39.918132Z",
     "shell.execute_reply": "2025-12-08T00:32:39.917443Z",
     "shell.execute_reply.started": "2025-12-08T00:32:39.914580Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Subtask 2 label names (update if more languages)\n",
    "SUBTASK2_LABELS = [\n",
    "    \"political\",\n",
    "    \"racial/ethnic\",\n",
    "    \"religious\",\n",
    "    \"gender/sexual\",\n",
    "    \"other\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Subtask-2 English Data\n",
    "\n",
    "Train path and dev path correspond to **train.csv** and **dev.csv** for Subtask 2.\n",
    "IMPORTANT:\n",
    "- Dev = test split (no gold labels for submission)\n",
    "- To evaluate locally, we will create a validation split from the train set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:32:42.902187Z",
     "iopub.status.busy": "2025-12-08T00:32:42.901618Z",
     "iopub.status.idle": "2025-12-08T00:32:42.942503Z",
     "shell.execute_reply": "2025-12-08T00:32:42.941892Z",
     "shell.execute_reply.started": "2025-12-08T00:32:42.902161Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id                                 text  \\\n",
      "0  zho_e59ce789a1d83d91cb7d362efaa3bf23           Â•Ω‰πÖÈÉΩÊ≤°ÊúâËßÅËøáÈÇ£‰πàÂπ≤ÂáÄÁöÑÁôΩ‰∫∫Áè≠Á∫ß‰∫ÜÔºå‰∏Ä‰∏™Èªë‰πêËâ≤ÈÉΩÊ≤°Êúâ   \n",
      "1  zho_ea3ef5567698fc40fa631baf7f697a16   Ê•º‰∏ªËøôËÆΩÂà∫Â§™ÊúâÂäõÂ∫¶ÊääË∑™Ëô´ÊóèÂíåÂõΩÈôÖÈ¨ºÂ≠êËô´Á±ªÂèäÂÖ∂ÂÆÉ‰ª¨Âêé‰ª£Ëô´Ê∑∑ÊèèÂÜôÊ∑ãÊºìÂ∞ΩËá¥   \n",
      "2  zho_b73779673957f6dab5688c27a6747458           ‰Ω†ËøôÊ†∑ËØ¥ËÆ©ÈÇ£‰∫õÊ†áÊ¶úÊâæ‰∏™Â§ñÂõΩÂØπË±°ÂÄçÊúâÈù¢ÁöÑ‰∫∫ËøòÊÄé‰πàË£ÖbÔøΩ   \n",
      "3  zho_f7164a14baafbcb6ec387b0217a1c766  ËØ¥Êòé‰∏Ä‰∏ãÔºåÊàëÂè™ÂÖ≥Áà±Ëá™Â∑±Ë∫´ËæπÁöÑÂ•≥ÊÄßÔºåÊØîÂ¶ÇËÄÅÂ©ÜÂ•≥ÂÑøÁ≠âÔºåÂà´ÁöÑÂ•≥‰∫∫ÂÖ≥ÊàëÈ∏ü‰∫ã„ÄÇv   \n",
      "4  zho_1be506c572b805494787f548671a5bb7          Âü∫‰Ω¨ËøòËØ¥‰πãÂâçËßÜÈ¢ëÈáåÁöÑ‰∏çÊòØÂÆÉÔºåÂÆÉÈÉΩËØ¥ÁÖßÁâáÊòØÂÆÉÁàÜÂá∫Êù•ÁöÑ‰∫Ü„ÄÇ   \n",
      "\n",
      "   political  racial/ethnic  religious  gender/sexual  other  \n",
      "0          0              1          0              0      0  \n",
      "1          0              1          0              0      0  \n",
      "2          0              1          0              0      0  \n",
      "3          0              0          0              1      0  \n",
      "4          0              0          0              1      0  \n",
      "Train size: 4280\n",
      "Test size: 214\n"
     ]
    }
   ],
   "source": [
    "train2_path = f\"{BASE_DATA}/subtask2/train/{LANG}.csv\"\n",
    "test2_path  = f\"{BASE_DATA}/subtask2/dev/{LANG}.csv\"\n",
    "\n",
    "train2_df = pd.read_csv(train2_path)\n",
    "test2_df  = pd.read_csv(test2_path)\n",
    "\n",
    "print(train2_df.head())\n",
    "print(\"Train size:\", len(train2_df))\n",
    "print(\"Test size:\", len(test2_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess and create train/validation split  \n",
    "We will mimic Subtask-1 behavior by splitting the official train set into:  \n",
    "- **train** (80%)  \n",
    "- **validation** (20%)  \n",
    "\n",
    "We also convert label columns to float32.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:32:45.807590Z",
     "iopub.status.busy": "2025-12-08T00:32:45.807304Z",
     "iopub.status.idle": "2025-12-08T00:32:45.963797Z",
     "shell.execute_reply": "2025-12-08T00:32:45.963084Z",
     "shell.execute_reply.started": "2025-12-08T00:32:45.807568Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtask2 pos_weight (capped): [5.0, 3.4467532634735107, 5.0, 5.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "# Clean text\n",
    "train2_df[\"text\"] = train2_df[\"text\"].apply(clean_text)\n",
    "test2_df[\"text\"]  = test2_df[\"text\"].apply(clean_text)\n",
    "\n",
    "# Train/validation split\n",
    "train2_df, val2_df = train_test_split(train2_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert multi-label columns to float32\n",
    "train2_df[SUBTASK2_LABELS] = train2_df[SUBTASK2_LABELS].astype(\"float32\")\n",
    "val2_df[SUBTASK2_LABELS]   = val2_df[SUBTASK2_LABELS].astype(\"float32\")\n",
    "\n",
    "# Pos weight for BCE (handle imbalance)\n",
    "pos_counts2 = train2_df[SUBTASK2_LABELS].sum().values\n",
    "neg_counts2 = len(train2_df) - pos_counts2\n",
    "pos_weight2 = torch.tensor(neg_counts2 / (pos_counts2 + 1e-6), dtype=torch.float)\n",
    "pos_weight2 = torch.clamp(pos_weight2, max=5.0)\n",
    "print(\"Subtask2 pos_weight (capped):\", pos_weight2.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to HuggingFace Dataset  \n",
    "We must produce a **single combined `labels` vector** per row for multi-label training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:32:48.226235Z",
     "iopub.status.busy": "2025-12-08T00:32:48.225951Z",
     "iopub.status.idle": "2025-12-08T00:32:48.697923Z",
     "shell.execute_reply": "2025-12-08T00:32:48.697069Z",
     "shell.execute_reply.started": "2025-12-08T00:32:48.226216Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4490592464cf46c6b230cda4fe04baa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3424 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3238e62bc04b6b9976e912a20edc69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_labels_sub2(example):\n",
    "    example[\"labels\"] = [float(example[col]) for col in SUBTASK2_LABELS]\n",
    "    return example\n",
    "\n",
    "train2_ds = Dataset.from_pandas(train2_df)\n",
    "val2_ds   = Dataset.from_pandas(val2_df)\n",
    "test2_ds  = Dataset.from_pandas(test2_df)  # for final predictions\n",
    "\n",
    "train2_ds = train2_ds.map(add_labels_sub2)\n",
    "val2_ds   = val2_ds.map(add_labels_sub2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize using the same tokenizer as Subtask-1  \n",
    "We reuse the tokenizer defined earlier (bert-base-multilingual-cased).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:32:51.279373Z",
     "iopub.status.busy": "2025-12-08T00:32:51.278667Z",
     "iopub.status.idle": "2025-12-08T00:32:52.371969Z",
     "shell.execute_reply": "2025-12-08T00:32:52.371168Z",
     "shell.execute_reply.started": "2025-12-08T00:32:51.279349Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21611c31d4094e7d92b79d2464083644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3424 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc759973c49a495fa9a3dcf580ef4f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2021210fb0430cbfbbd08034f020ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/214 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train2_ds = train2_ds.map(tokenize, batched=True)\n",
    "val2_ds   = val2_ds.map(tokenize, batched=True)\n",
    "test2_ds  = test2_ds.map(tokenize, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set PyTorch format  \n",
    "Only include:\n",
    "- input_ids  \n",
    "- attention_mask  \n",
    "- labels  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:32:56.863835Z",
     "iopub.status.busy": "2025-12-08T00:32:56.863255Z",
     "iopub.status.idle": "2025-12-08T00:32:56.869104Z",
     "shell.execute_reply": "2025-12-08T00:32:56.868459Z",
     "shell.execute_reply.started": "2025-12-08T00:32:56.863811Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train2_ds.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")\n",
    "val2_ds.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")\n",
    "\n",
    "test2_ds.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Multilingual BERT for Multi-Label Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:32:58.838788Z",
     "iopub.status.busy": "2025-12-08T00:32:58.838119Z",
     "iopub.status.idle": "2025-12-08T00:33:07.399592Z",
     "shell.execute_reply": "2025-12-08T00:33:07.398806Z",
     "shell.execute_reply.started": "2025-12-08T00:32:58.838748Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362308a96ccb43d199bd28b0b15f0e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/LaBSE and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model2 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(SUBTASK2_LABELS),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrainingArguments  \n",
    "We reuse the same training parameters as Subtask-1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:33:08.452008Z",
     "iopub.status.busy": "2025-12-08T00:33:08.451414Z",
     "iopub.status.idle": "2025-12-08T00:33:08.480770Z",
     "shell.execute_reply": "2025-12-08T00:33:08.479988Z",
     "shell.execute_reply.started": "2025-12-08T00:33:08.451982Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args2 = TrainingArguments(\n",
    "    output_dir=\"/kaggle/temp/subtask2\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    learning_rate=SUBTASK2_LR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM,\n",
    "    # per_device_train_batch_size=4,\n",
    "    # per_device_eval_batch_size=16,\n",
    "    # gradient_accumulation_steps=2,\n",
    "    num_train_epochs=SUBTASK2_EPOCHS,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macro F1 across all 5 labels  \n",
    "Threshold applied after sigmoid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:33:14.490226Z",
     "iopub.status.busy": "2025-12-08T00:33:14.489567Z",
     "iopub.status.idle": "2025-12-08T00:33:14.494162Z",
     "shell.execute_reply": "2025-12-08T00:33:14.493507Z",
     "shell.execute_reply.started": "2025-12-08T00:33:14.490200Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics_sub2(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "    score = f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "    return {\"macro_f1\": float(score)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Subtask-2 Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:33:17.537142Z",
     "iopub.status.busy": "2025-12-08T00:33:17.536853Z",
     "iopub.status.idle": "2025-12-08T00:33:19.094871Z",
     "shell.execute_reply": "2025-12-08T00:33:19.094038Z",
     "shell.execute_reply.started": "2025-12-08T00:33:17.537121Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Path (<tt>submissions/subtask1/pred_eng.csv</tt>) doesn't exist. It may still be in the process of being generated, or you may have the incorrect path."
      ],
      "text/plain": [
       "/kaggle/working/submissions/subtask1/pred_eng.csv"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from IPython.display import FileLink\n",
    "\n",
    "# FileLink('submissions/subtask1/pred_eng.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:33:21.178324Z",
     "iopub.status.busy": "2025-12-08T00:33:21.177748Z",
     "iopub.status.idle": "2025-12-08T00:33:21.583839Z",
     "shell.execute_reply": "2025-12-08T00:33:21.583052Z",
     "shell.execute_reply.started": "2025-12-08T00:33:21.178296Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T00:33:23.985147Z",
     "iopub.status.busy": "2025-12-08T00:33:23.984853Z",
     "iopub.status.idle": "2025-12-08T01:02:21.742314Z",
     "shell.execute_reply": "2025-12-08T01:02:21.741735Z",
     "shell.execute_reply.started": "2025-12-08T00:33:23.985125Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47/506938794.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `BCETrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4280' max='4280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4280/4280 28:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.379600</td>\n",
       "      <td>0.425677</td>\n",
       "      <td>0.688698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.320300</td>\n",
       "      <td>0.413392</td>\n",
       "      <td>0.721575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.233100</td>\n",
       "      <td>0.435285</td>\n",
       "      <td>0.723637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.529567</td>\n",
       "      <td>0.736052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.629575</td>\n",
       "      <td>0.739375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.645438</td>\n",
       "      <td>0.717180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.694576</td>\n",
       "      <td>0.744327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.675540</td>\n",
       "      <td>0.751165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>0.741399</td>\n",
       "      <td>0.745970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.741807</td>\n",
       "      <td>0.744971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4280, training_loss=0.1459432421478434, metrics={'train_runtime': 1730.8391, 'train_samples_per_second': 19.782, 'train_steps_per_second': 2.473, 'total_flos': 3941509774110720.0, 'train_loss': 0.1459432421478434, 'epoch': 10.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2 = BCETrainer(\n",
    "    model=model2,\n",
    "    args=training_args2,\n",
    "    train_dataset=train2_ds,\n",
    "    eval_dataset=val2_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_sub2,\n",
    "    pos_weight=pos_weight2,\n",
    ")\n",
    "\n",
    "trainer2.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-07T01:19:30.472Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from IPython.display import FileLink\n",
    "\n",
    "# FileLink(f'submissions/subtask2/pred_{LANG}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:02:53.467501Z",
     "iopub.status.busy": "2025-12-08T01:02:53.467221Z",
     "iopub.status.idle": "2025-12-08T01:02:53.881535Z",
     "shell.execute_reply": "2025-12-08T01:02:53.880963Z",
     "shell.execute_reply.started": "2025-12-08T01:02:53.467482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions for submission  \n",
    "(You will combine these later inside `subtask_2/pred_eng.csv`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-07T01:19:30.472Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def tune_per_label_threshold(logits, labels, grid=None):\n",
    "#     grid = grid or np.linspace(0.1, 0.8, 15)\n",
    "#     probs = 1 / (1 + np.exp(-logits))\n",
    "#     best = []\n",
    "#     for i in range(labels.shape[1]):\n",
    "#         best_f1, best_t = -1, 0.5\n",
    "#         for t in grid:\n",
    "#             preds = (probs[:, i] >= t).astype(int)\n",
    "#             f1 = f1_score(labels[:, i], preds, zero_division=0)\n",
    "#             if f1 > best_f1:\n",
    "#                 best_f1, best_t = f1, t\n",
    "#         best.append(best_t)\n",
    "#     return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:02:57.699565Z",
     "iopub.status.busy": "2025-12-08T01:02:57.699294Z",
     "iopub.status.idle": "2025-12-08T01:03:05.069344Z",
     "shell.execute_reply": "2025-12-08T01:03:05.068806Z",
     "shell.execute_reply.started": "2025-12-08T01:02:57.699548Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best macro threshold: 0.30 | F1=0.7560\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>political</th>\n",
       "      <th>racial/ethnic</th>\n",
       "      <th>religious</th>\n",
       "      <th>gender/sexual</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zho_3653010632292449856c11f234040704</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zho_f186c48ab10bbad0110cc57f81929208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zho_cc96cfb2e302edf570548253578ced89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zho_6d06ab3b817c68c5bab057add5b06447</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zho_ffe6eda7b6330733276218813605d369</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  political  racial/ethnic  religious  \\\n",
       "0  zho_3653010632292449856c11f234040704          0              1          0   \n",
       "1  zho_f186c48ab10bbad0110cc57f81929208          0              0          0   \n",
       "2  zho_cc96cfb2e302edf570548253578ced89          0              0          0   \n",
       "3  zho_6d06ab3b817c68c5bab057add5b06447          0              1          0   \n",
       "4  zho_ffe6eda7b6330733276218813605d369          0              1          0   \n",
       "\n",
       "   gender/sexual  other  \n",
       "0              0      0  \n",
       "1              0      1  \n",
       "2              0      1  \n",
       "3              0      0  \n",
       "4              0      0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def tune_macro_threshold(logits, labels, grid=None):\n",
    "    grid = grid or np.linspace(0.1, 0.8, 15)\n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    best_f1, best_t = -1, 0.5\n",
    "    for t in grid:\n",
    "        preds = (probs >= t).astype(int)\n",
    "        f1 = f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    return best_t, best_f1\n",
    "\n",
    "# Tune threshold on validation (after trainer2.train(), using the best checkpoint)\n",
    "val_pred2 = trainer2.predict(val2_ds)\n",
    "best_t, best_f1 = tune_macro_threshold(val_pred2.predictions, val_pred2.label_ids)\n",
    "print(f\"Best macro threshold: {best_t:.2f} | F1={best_f1:.4f}\")\n",
    "\n",
    "# Predict on test/dev with that threshold\n",
    "pred_logits = trainer2.predict(test2_ds).predictions\n",
    "pred_probs = 1 / (1 + np.exp(-pred_logits))\n",
    "pred_labels = (pred_probs >= best_t).astype(int)\n",
    "\n",
    "sub2_out = pd.DataFrame({\"id\": test2_df[\"id\"]})\n",
    "for i, col in enumerate(SUBTASK2_LABELS):\n",
    "    sub2_out[col] = pred_labels[:, i]\n",
    "\n",
    "sub2_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:03:26.639007Z",
     "iopub.status.busy": "2025-12-08T01:03:26.638396Z",
     "iopub.status.idle": "2025-12-08T01:03:26.649473Z",
     "shell.execute_reply": "2025-12-08T01:03:26.648730Z",
     "shell.execute_reply.started": "2025-12-08T01:03:26.638984Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'submissions/subtask2/pred_zho.csv'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "SAVE_DIR = \"submissions/subtask2\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "out_path = f\"{SAVE_DIR}/pred_{LANG}.csv\"\n",
    "sub2_out.to_csv(out_path, index=False)\n",
    "out_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------\n",
    "# Subtask 3 ‚Äî Manifestation Identification (Multi-Label)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "Subtask 3 predicts **how** polarization is expressed in the text.\n",
    "\n",
    "Labels in this subtask:\n",
    "\n",
    "- stereotype  \n",
    "- vilification  \n",
    "- dehumanization  \n",
    "- extreme_language  \n",
    "- lack_of_empathy  \n",
    "- invalidation\n",
    "\n",
    "This is a **multi-label classification** task:\n",
    "a single text may contain multiple manifestations.\n",
    "\n",
    "As before, we will:\n",
    "\n",
    "- preprocess text  \n",
    "- split train ‚Üí train/val  \n",
    "- build a single multi-label `labels` vector  \n",
    "- train a Transformer with BCEWithLogitsLoss  \n",
    "- evaluate using Macro-F1  \n",
    "- generate predictions for Codabench submission  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:16:58.889220Z",
     "iopub.status.busy": "2025-12-08T01:16:58.888931Z",
     "iopub.status.idle": "2025-12-08T01:16:59.258723Z",
     "shell.execute_reply": "2025-12-08T01:16:59.257792Z",
     "shell.execute_reply.started": "2025-12-08T01:16:58.889198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:16:59.260862Z",
     "iopub.status.busy": "2025-12-08T01:16:59.260520Z",
     "iopub.status.idle": "2025-12-08T01:16:59.385689Z",
     "shell.execute_reply": "2025-12-08T01:16:59.384767Z",
     "shell.execute_reply.started": "2025-12-08T01:16:59.260832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SUBTASK3_LABELS = [\n",
    "    \"stereotype\",\n",
    "    \"vilification\",\n",
    "    \"dehumanization\",\n",
    "    \"extreme_language\",\n",
    "    \"lack_of_empathy\",\n",
    "    \"invalidation\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Subtask-3 English Data\n",
    "\n",
    "Same structure as previous subtasks:\n",
    "\n",
    "- train/eng.csv  \n",
    "- dev/eng.csv (this is the test set for submission)\n",
    "\n",
    "We will create our own validation split from the train set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:16:59.386850Z",
     "iopub.status.busy": "2025-12-08T01:16:59.386600Z",
     "iopub.status.idle": "2025-12-08T01:16:59.455951Z",
     "shell.execute_reply": "2025-12-08T01:16:59.455209Z",
     "shell.execute_reply.started": "2025-12-08T01:16:59.386833Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id                                 text  \\\n",
      "0  zho_e59ce789a1d83d91cb7d362efaa3bf23           Â•Ω‰πÖÈÉΩÊ≤°ÊúâËßÅËøáÈÇ£‰πàÂπ≤ÂáÄÁöÑÁôΩ‰∫∫Áè≠Á∫ß‰∫ÜÔºå‰∏Ä‰∏™Èªë‰πêËâ≤ÈÉΩÊ≤°Êúâ   \n",
      "1  zho_ea3ef5567698fc40fa631baf7f697a16   Ê•º‰∏ªËøôËÆΩÂà∫Â§™ÊúâÂäõÂ∫¶ÊääË∑™Ëô´ÊóèÂíåÂõΩÈôÖÈ¨ºÂ≠êËô´Á±ªÂèäÂÖ∂ÂÆÉ‰ª¨Âêé‰ª£Ëô´Ê∑∑ÊèèÂÜôÊ∑ãÊºìÂ∞ΩËá¥   \n",
      "2  zho_b73779673957f6dab5688c27a6747458           ‰Ω†ËøôÊ†∑ËØ¥ËÆ©ÈÇ£‰∫õÊ†áÊ¶úÊâæ‰∏™Â§ñÂõΩÂØπË±°ÂÄçÊúâÈù¢ÁöÑ‰∫∫ËøòÊÄé‰πàË£ÖbÔøΩ   \n",
      "3  zho_f7164a14baafbcb6ec387b0217a1c766  ËØ¥Êòé‰∏Ä‰∏ãÔºåÊàëÂè™ÂÖ≥Áà±Ëá™Â∑±Ë∫´ËæπÁöÑÂ•≥ÊÄßÔºåÊØîÂ¶ÇËÄÅÂ©ÜÂ•≥ÂÑøÁ≠âÔºåÂà´ÁöÑÂ•≥‰∫∫ÂÖ≥ÊàëÈ∏ü‰∫ã„ÄÇv   \n",
      "4  zho_1be506c572b805494787f548671a5bb7          Âü∫‰Ω¨ËøòËØ¥‰πãÂâçËßÜÈ¢ëÈáåÁöÑ‰∏çÊòØÂÆÉÔºåÂÆÉÈÉΩËØ¥ÁÖßÁâáÊòØÂÆÉÁàÜÂá∫Êù•ÁöÑ‰∫Ü„ÄÇ   \n",
      "\n",
      "   stereotype  vilification  dehumanization  extreme_language  \\\n",
      "0           1             1               1                 0   \n",
      "1           0             1               1                 0   \n",
      "2           1             0               0                 0   \n",
      "3           0             0               0                 0   \n",
      "4           0             1               0                 0   \n",
      "\n",
      "   lack_of_empathy  invalidation  \n",
      "0                0             0  \n",
      "1                0             0  \n",
      "2                0             0  \n",
      "3                1             1  \n",
      "4                0             0  \n",
      "Train size: 4280\n",
      "Test size: 214\n"
     ]
    }
   ],
   "source": [
    "train3_path = f\"{BASE_DATA}/subtask3/train/{LANG}.csv\"\n",
    "test3_path  = f\"{BASE_DATA}/subtask3/dev/{LANG}.csv\"\n",
    "\n",
    "train3_df = pd.read_csv(train3_path)\n",
    "test3_df  = pd.read_csv(test3_path)\n",
    "\n",
    "print(train3_df.head())\n",
    "print(\"Train size:\", len(train3_df))\n",
    "print(\"Test size:\", len(test3_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess text & split dataset  \n",
    "We follow the same approach as Subtask-1 & Subtask-2:\n",
    "\n",
    "- Clean text using `clean_text()`\n",
    "- Split train into 80% train, 20% validation\n",
    "- Convert the label columns to float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:16:59.458093Z",
     "iopub.status.busy": "2025-12-08T01:16:59.457763Z",
     "iopub.status.idle": "2025-12-08T01:16:59.638886Z",
     "shell.execute_reply": "2025-12-08T01:16:59.638088Z",
     "shell.execute_reply.started": "2025-12-08T01:16:59.458069Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtask3 pos_weight: [2.3242719173431396, 4.400630950927734, 20.006134033203125, 11.588234901428223, 12.220077514648438, 20.267080307006836]\n"
     ]
    }
   ],
   "source": [
    "# Clean text\n",
    "train3_df[\"text\"] = train3_df[\"text\"].apply(clean_text)\n",
    "test3_df[\"text\"]  = test3_df[\"text\"].apply(clean_text)\n",
    "\n",
    "# Train/validation split\n",
    "train3_df, val3_df = train_test_split(train3_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to float32\n",
    "train3_df[SUBTASK3_LABELS] = train3_df[SUBTASK3_LABELS].astype(\"float32\")\n",
    "val3_df[SUBTASK3_LABELS]   = val3_df[SUBTASK3_LABELS].astype(\"float32\")\n",
    "\n",
    "# Pos weight for BCE\n",
    "pos_counts3 = train3_df[SUBTASK3_LABELS].sum().values\n",
    "neg_counts3 = len(train3_df) - pos_counts3\n",
    "pos_weight3 = torch.tensor(neg_counts3 / (pos_counts3 + 1e-6), dtype=torch.float)\n",
    "print(\"Subtask3 pos_weight:\", pos_weight3.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to HuggingFace Dataset  \n",
    "We build a single `labels` vector for multi-label classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:16:59.639847Z",
     "iopub.status.busy": "2025-12-08T01:16:59.639651Z",
     "iopub.status.idle": "2025-12-08T01:17:00.169798Z",
     "shell.execute_reply": "2025-12-08T01:17:00.169030Z",
     "shell.execute_reply.started": "2025-12-08T01:16:59.639831Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4570bf38d3a415191872567b2e974a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3424 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a9957493e4441bb28421b8c868c257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_labels_sub3(example):\n",
    "    example[\"labels\"] = [float(example[col]) for col in SUBTASK3_LABELS]\n",
    "    return example\n",
    "\n",
    "train3_ds = Dataset.from_pandas(train3_df)\n",
    "val3_ds   = Dataset.from_pandas(val3_df)\n",
    "test3_ds  = Dataset.from_pandas(test3_df)\n",
    "\n",
    "train3_ds = train3_ds.map(add_labels_sub3)\n",
    "val3_ds   = val3_ds.map(add_labels_sub3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize using the same tokenizer  \n",
    "Using identical settings ensures consistency across subtasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:17:00.170805Z",
     "iopub.status.busy": "2025-12-08T01:17:00.170569Z",
     "iopub.status.idle": "2025-12-08T01:17:01.215065Z",
     "shell.execute_reply": "2025-12-08T01:17:01.214304Z",
     "shell.execute_reply.started": "2025-12-08T01:17:00.170780Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee880e6eb96e44fd96c8e414e66f4c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3424 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ee20003cb2431aa7c1ee31a340da9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7517240935b4ccdac17d19f7eee4ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/214 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train3_ds = train3_ds.map(tokenize, batched=True)\n",
    "# val3_ds   = val3_ds.map(tokenize, batched=True)\n",
    "# test3_ds  = test3_ds.map(tokenize, batched=True)\n",
    "\n",
    "\n",
    "MAX_LEN = 160  # temporary for Subtask 3\n",
    "train3_ds = train3_ds.map(tokenize, batched=True)\n",
    "val3_ds   = val3_ds.map(tokenize, batched=True)\n",
    "test3_ds  = test3_ds.map(tokenize, batched=True)\n",
    "MAX_LEN = 224  # restore if needed later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dataset format for Trainer  \n",
    "Only include:\n",
    "\n",
    "- input_ids  \n",
    "- attention_mask  \n",
    "- labels  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:17:01.216244Z",
     "iopub.status.busy": "2025-12-08T01:17:01.215973Z",
     "iopub.status.idle": "2025-12-08T01:17:01.222735Z",
     "shell.execute_reply": "2025-12-08T01:17:01.222032Z",
     "shell.execute_reply.started": "2025-12-08T01:17:01.216217Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train3_ds.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")\n",
    "val3_ds.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")\n",
    "\n",
    "test3_ds.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Transformer for Multi-Label Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:17:01.223774Z",
     "iopub.status.busy": "2025-12-08T01:17:01.223517Z",
     "iopub.status.idle": "2025-12-08T01:17:07.877435Z",
     "shell.execute_reply": "2025-12-08T01:17:07.876719Z",
     "shell.execute_reply.started": "2025-12-08T01:17:01.223753Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bdd12f075d843aabb67a05f105f490b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/LaBSE and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model3 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(SUBTASK3_LABELS),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrainingArguments  \n",
    "We reuse the same hyperparameters as Subtask-1 and 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:17:07.878425Z",
     "iopub.status.busy": "2025-12-08T01:17:07.878202Z",
     "iopub.status.idle": "2025-12-08T01:17:07.907369Z",
     "shell.execute_reply": "2025-12-08T01:17:07.906642Z",
     "shell.execute_reply.started": "2025-12-08T01:17:07.878407Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args3 = TrainingArguments(\n",
    "    output_dir=\"/kaggle/temp/subtask3\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    learning_rate=SUBTASK3_LR,\n",
    "    \n",
    "    # per_device_train_batch_size=8,\n",
    "    # per_device_eval_batch_size=32,\n",
    "    # gradient_accumulation_steps=4,\n",
    "    \n",
    "    # per_device_train_batch_size=4,\n",
    "    # per_device_eval_batch_size=16,\n",
    "    # gradient_accumulation_steps=4,\n",
    "    \n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    \n",
    "    num_train_epochs=SUBTASK3_EPOCHS,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    # weight_decay=WEIGHT_DECAY,\n",
    "    weight_decay=0.02,\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    label_smoothing_factor=0.05,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macro F1 across all 6 labels  \n",
    "Using sigmoid activation + threshold 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:17:07.909467Z",
     "iopub.status.busy": "2025-12-08T01:17:07.909185Z",
     "iopub.status.idle": "2025-12-08T01:17:08.147909Z",
     "shell.execute_reply": "2025-12-08T01:17:08.147025Z",
     "shell.execute_reply.started": "2025-12-08T01:17:07.909451Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics_sub3(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "    score = f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "    return {\"macro_f1\": float(score)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Subtask-3 Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:17:08.148825Z",
     "iopub.status.busy": "2025-12-08T01:17:08.148652Z",
     "iopub.status.idle": "2025-12-08T01:17:08.535748Z",
     "shell.execute_reply": "2025-12-08T01:17:08.534823Z",
     "shell.execute_reply.started": "2025-12-08T01:17:08.148810Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T01:17:08.536868Z",
     "iopub.status.busy": "2025-12-08T01:17:08.536648Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47/506938794.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `BCETrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1341' max='2140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1341/2140 09:35 < 05:43, 2.33 it/s, Epoch 3.13/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.819500</td>\n",
       "      <td>0.960700</td>\n",
       "      <td>0.458859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.834463</td>\n",
       "      <td>0.487733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.454400</td>\n",
       "      <td>0.976924</td>\n",
       "      <td>0.538017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer3 = BCETrainer(\n",
    "    model=model3,\n",
    "    args=training_args3,\n",
    "    train_dataset=train3_ds,\n",
    "    eval_dataset=val3_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_sub3,\n",
    "    pos_weight=pos_weight3,\n",
    ")\n",
    "\n",
    "trainer3.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions for submission  \n",
    "We apply sigmoid + 0.5 thresholding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# val_pred3 = trainer3.predict(val3_ds)\n",
    "# best_threshold_sub3, best_val_f1_sub3 = tune_multilabel_threshold(val_pred3.predictions, val_pred3.label_ids)\n",
    "# print(f\"Best val threshold (Subtask 3): {best_threshold_sub3:.2f} | F1={best_val_f1_sub3:.4f}\")\n",
    "\n",
    "# pred_logits_3 = trainer3.predict(test3_ds).predictions\n",
    "# pred_probs_3 = 1 / (1 + np.exp(-pred_logits_3))\n",
    "# pred_labels_3 = (pred_probs_3 >= best_threshold_sub3).astype(int)\n",
    "\n",
    "# sub3_out = pd.DataFrame({\n",
    "#     \"id\": test3_df[\"id\"],\n",
    "# })\n",
    "\n",
    "# for i, col in enumerate(SUBTASK3_LABELS):\n",
    "#     sub3_out[col] = pred_labels_3[:, i]\n",
    "\n",
    "# sub3_out.head()\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def tune_macro_threshold(logits, labels, grid=None):\n",
    "    grid = grid or np.linspace(0.1, 0.8, 15)\n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    best_f1, best_t = -1, 0.5\n",
    "    for t in grid:\n",
    "        preds = (probs >= t).astype(int)\n",
    "        f1 = f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    return best_t, best_f1\n",
    "\n",
    "val_pred3 = trainer3.predict(val3_ds)\n",
    "best_t3, best_f1_3 = tune_macro_threshold(val_pred3.predictions, val_pred3.label_ids)\n",
    "print(f\"Best macro threshold (Subtask 3): {best_t3:.2f} | F1={best_f1_3:.4f}\")\n",
    "\n",
    "pred_logits_3 = trainer3.predict(test3_ds).predictions\n",
    "pred_probs_3 = 1 / (1 + np.exp(-pred_logits_3))\n",
    "pred_labels_3 = (pred_probs_3 >= best_t3).astype(int)\n",
    "\n",
    "sub3_out = pd.DataFrame({\"id\": test3_df[\"id\"]})\n",
    "for i, col in enumerate(SUBTASK3_LABELS):\n",
    "    sub3_out[col] = pred_labels_3[:, i]\n",
    "\n",
    "sub3_out.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "SAVE_DIR = \"submissions/subtask3\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "out_path3 = f\"{SAVE_DIR}/pred_{LANG}.csv\"\n",
    "sub3_out.to_csv(out_path3, index=False)\n",
    "out_path3\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8912684,
     "sourceId": 13982677,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
